# Support

Welcome to the support page for the **Pose Data Annotator** app. You can find the most frequent questions here. 

If you have a question, feel free to contact us at [matyas.bohacek@matsworld.io](mailto:matyas.bohacek@matsworld.io). If you have a suggestion, feature request, or want to file a bug report, proceed [here](https://github.com/thanhdolong/sign-language-recognition-trainer/issues/new/choose).

### How to annotate a single video?

1. Open the app.
2. Select the **Annotate video** section in the left sidebar.
3. Drop a file into the box, or select one using the **Load Video** button.
4. Tap **Start Processing** and wait for the results. A popup will open once the process is done and you will be able to save the resulting `csv` file.

### How to annotate a dataset?

1. Open the app.
2. Select the **Annotate dataset** section in the left sidebar.
3. Drop a folder into the box, or select one using the **Load Dataset** button.
4. Tap **Start Processing** and wait for the results. A popup will open once the process is done and you will be able to save the resulting `csv` file.

### How does the app work?

The app utilizes the **Vision** engine for body, hand and face pose estimation. The videos are split into frames individually annotated and outputted for any potential experiments or use-cases involving pose data.

### How to customize the annotations?

Open **App Preferences** (by pressing `Cmd + ,`). Here you can customize the FPS to be used, which parts of the body to annotate, and more.
